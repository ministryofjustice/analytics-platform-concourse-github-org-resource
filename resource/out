#!/usr/bin/env python

from moj_analytics.concourse import Resource
import requests

from common import get_all, get_org, pushed_at


fly = '/usr/local/bin/fly'


@Resource
def create_pipelines(src_dir, source={}, params={}):
    print('Fetching existing pipelines')
    pipelines = get_pipelines(**source)

    print(f'Fetching {source["name"]} org')
    org = get_org(**source)

    print('Fetching org repos')
    repos = get_all(org['repo_url'], **source)

    for repo in repos:
        if repo['name'] in pipelines:
            continue

        if buildfile_exists(repo, **source):
            print(f'Creating pipeline for {repo["name"]}')
            fly_login(**source)
            fly_set_pipeline(repo, **source)

    timestamps = sorted(set(map(pushed_at, repos)))

    return {'version': {'ref': timestamps[-1]}}


def get_pipelines(concourse_url, team_name, **kwargs):
    pipelines = requests.get(
        f'{concourse_url}/api/v1/teams/{team_name}/pipelines'
    ).json()
    return [p['name'] for p in pipelines if p['team_name'] == team_name]


def buildfile_exists(repo, **kwargs):
    url = repo['contents_url'].replace('{+path}', 'Jenkinsfile')
    return github_api_request(url, **kwargs).status_code != 404


def fly_login(**source):
    subprocess.run(
        f'{fly} -t dev login -u {username} -p {password} -n {team_name}',
        check=True)


def fly_set_pipeline(repo, **kwargs):
    subprocess.run(
        f'{fly} -t dev set-pipeline -p {repo} -c pipeline.yaml -n',
        check=True)


if __name__ == '__main__':
    create_pipelines()
